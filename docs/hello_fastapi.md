# ‚ö° Hello FastAPI

<figure markdown>
  ![logo FastAPI](imgs/fastapi.png)
  <figcaption></figcaption>
</figure>

√â chegada a t√£o esperada hora de escrevermos c√≥digo, por√©m, como aprendemos que podemos ser guiados por testes para ajudar a concep√ß√£o da arquitetura do nosso programa, faremos as coisas um pouco diferente.

Utilizaremos os ciclos do TDD para nos auxiliarem e assim garantiremos uma qualidade de c√≥digo ao final.

Est√£o lembrados o que √© a nossa aplica√ß√£o? Caso n√£o se recorde leia as [regras de neg√≥cio](./planejando.md) novamente.

Vamos dividir algumas tarefas ent√£o, na nossa lista de funcionalidades:

- [ ] listar as tarefas
- [ ] adicionar tarefa
- [ ] remover tarefa
- [ ] ordenar a listagem por estado
- [ ] finalizar uma tarefa
- [ ] exibir uma tarefa de forma detalhada

Acho que para iniciarmos o mais simples de escrever e testar √© a funcionalidade de listagem de tarefas.

Mas como fazer isto se n√£o temos tarefas, nem mesmo uma aplica√ß√£o ainda? Por onde come√ßo?

Inicie criando um diret√≥rio com o nome `tests`, onde colocaremos os testes do nosso programa.

L√° dentro, crie um arquivo com nome `test_gerenciador.py` que deve ficar da seguinte maneira.

```
.
‚îú‚îÄ‚îÄ dev-requirements.txt
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ tests
    ‚îî‚îÄ‚îÄ test_gerenciador.py
```

Agora vamos escrever nosso primeiro teste!

Nossa listagem de tarefas, se bem sucedida, deve retornar o c√≥digo de status `200 OK` e este ser√° nosso primeiro teste.

Traduzindo em um teste automatizado que deve ser acrescentado ao arquivo test_gerenciador.py.

```python
from fastapi.testclient import TestClient
from fastapi import status
from gerenciador_tarefas import app


def test_quando_listar_tarefas_devo_ter_como_retorno_codigo_de_status_200():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.status_code == status.HTTP_200_OK
```

Vamos rodar pela primeira vez os testes no nosso projeto.

`python -m pytest`

üò± Nossa! Ocorreu um erro!

```
$ python -m pytest
========================================================= test session starts =========================================================
platform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0
rootdir: /home/cassiobotaro/Projects/gerenciador-tarefas
plugins: anyio-3.6.1
collected 0 items / 1 error

=============================================================== ERRORS ================================================================
_____________________________________________ ERROR collecting tests/test_gerenciador.py ______________________________________________
ImportError while importing test module '/home/cassiobotaro/Projects/gerenciador-tarefas/tests/test_gerenciador.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
../../.asdf/installs/python/3.10.4/lib/python3.10/importlib/__init__.py:126: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/test_gerenciador.py:3: in <module>
    from gerenciador_tarefas.gerenciador import app
E   ModuleNotFoundError: No module named 'gerenciador_tarefas.gerenciador'
======================================================= short test summary info =======================================================
ERROR tests/test_gerenciador.py
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
========================================================== 1 error in 0.30s ===========================================================

```

N√£o se desespere, √© que temos um teste, mas ainda n√£o come√ßamos a escrever c√≥digo da nossa aplica√ß√£o.

A primeira coisa que precisamos fazer √© criar um  diret√≥rio onde colocaremos nossos c√≥digos. vamos chama-lo de `gerenciador_tarefas`.

Dentro dele criamos um novo arquivo `gerenciador.py`, e neste arquivo vamos iniciar uma aplica√ß√£o da seguinte maneira.

```
.
‚îú‚îÄ‚îÄ dev-requirements.txt
‚îú‚îÄ‚îÄ gerenciador_tarefas
‚îÇ   ‚îî‚îÄ‚îÄ gerenciador.py
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ tests
    ‚îî‚îÄ‚îÄ test_gerenciador.py
```

O conte√∫do desse arquivo ser√° o seguinte.

```python
from fastapi import FastAPI


app = FastAPI()
```

Isto √© uma maneira de fazer os testes conhecerem o c√≥digo da nossa aplica√ß√£o. Toda vez que precisamos de um trecho de c√≥digo em outro arquivo devemos fazer a "importa√ß√£o" daquele trecho utilizando o comando import.

Neste caso estamos requisitando a aplica√ß√£o nos arquivos de testes automatizados, para escrevermos os testes necess√°rios.

Rode novamente os testes.

`python -m pytest`

‚ùå Os testes continuam falhando!

```python
# ...
>       assert resposta.status_code == status.HTTP_200_OK
E       assert 404 == 200
E        +  where 404 = <Response [404]>.status_code
E        +  and   200 = status.HTTP_200_OK
# ...
```

O teste est√° dizendo que esper√°mos um c√≥digo de status de sucesso, por√©m o recurso (`tarefas`) n√£o foi encontrado, por isso o c√≥digo 404.

Agora temos nossa aplica√ß√£o, mas nosso recurso de tarefas ainda n√£o foi criado.

No arquivo `gerenciador.py` adicione a seguinte fun√ß√£o.

```python
@app.get("/tarefas")
def listar():
    return ""
```

Rode novamente os testes.

`python -m pytest`

```python
$ python -m pytest
========================================================= test session starts =========================================================
platform linux -- Python 3.10.4, pytest-7.1.2, pluggy-1.0.0
rootdir: /home/cassiobotaro/Projects/gerenciador-tarefas
plugins: anyio-3.6.1
collected 1 item

tests/test_gerenciador.py .                                                                                                     [100%]

========================================================== 1 passed in 0.23s ==========================================================
```

‚úÖ Legal! Temos um teste funcionando! Nossa aplica√ß√£o est√° retornando status 200 OK, ainda que a funcionalidade completa n√£o esteja pronta.

üë∂ Damos o nome de `baby step`, esta maneira de construir uma aplica√ß√£o dando pequenos passos de cada vez.

Nosso recurso deve ter o formato [json](http://json.org/), que √© um formato textual estruturado, bem simples e leve para troca de informa√ß√µes.

Mas como checamos isto?

Vamos escrever um novo teste!

No arquivo `test_gerenciador.py`, adicione o seguinte teste.

```python
def test_quando_listar_tarefas_formato_de_retorno_deve_ser_json():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.headers["Content-Type"] == "application/json"
```

Rode os testes novamente. Caso esque√ßa o comando, volte um pouco atr√°s e copie.

Uai? O novo teste est√° passando ?!?!

Acontece que por padr√£o, o fastapi j√° define que o formato ser√° "json".

Normalmente, queremos que testes falhem, por√©m este teste pode ser √∫til como documenta√ß√£o do seu recurso.

Vamos deixa-lo e vamos seguir em frente, mas agora tentando escrever um teste que realmente falhe.

Quando listar tarefas o retorno deve possuir o formato de lista. Transformando isto em c√≥digo temos:

```python
def test_quando_listar_tarefas_retorno_deve_ser_uma_lista():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert isinstance(resposta.json(), list)
```

E vamos continuar o nosso ciclo e rodar os testes.

‚ùå O teste falha e isto √© bom!

Acontece que nosso retorno n√£o √© uma lista. Mas como corrigir isto?

Se temos um teste que falha, precisamos escrever o c√≥digo necess√°rio para este teste passar.

Vamos voltar ao nosso gerenciador.py para corrigir o nosso problema. Na fun√ß√£o que exp√µe o nosso recurso, modifique o c√≥digo para:

```python
@app.get("/tarefas")
def listar():
    return []
```

Corrigido o c√≥digo, rode novamente os testes.

‚úÖ Aew! Testes est√£o passando novamente!


Neste passo os arquivos devem estar da seguinte maneira.

**test_gerenciador.py**
```python
from fastapi.testclient import TestClient
from fastapi import status
from gerenciador_tarefas.gerenciador import app


def test_quando_listar_tarefas_devo_ter_como_retorno_codigo_de_status_200():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.status_code == status.HTTP_200_OK


def test_quando_listar_tarefas_formato_de_retorno_deve_ser_json():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.headers["Content-Type"] == "application/json"


def test_quando_listar_tarefas_retorno_deve_ser_uma_lista():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert isinstance(resposta.json(), list)
```

**gerenciador.py**
```python
from fastapi import FastAPI


app = FastAPI()


@app.get("/tarefas")
def listar():
    return []
```

Repare que pouco a pouco nossa aplica√ß√£o vai tomando forma a partir dos testes.

Parece chato ter de ficar rodando os testes a cada vez, mas al√©m de garatir a qualidade do c√≥digo, cada vez que os testes s√£o rodados, todas as funcionalidades testadas anteriormente s√£o verificadas novamente. Assim voc√™ evita ter de lembrar todas as possibilidades a serem testadas em um teste manual.

üö¶ Perceberam que estamos guiando o nosso desenvolvimento a partir dos testes? Pouco a pouco temos a funcionalidade de listagem sendo desenhada.

Vamos continuar ent√£o. Sabemos que quando n√£o h√° tarefas, nossa resposta do recurso deve ser uma lista vazia.

Mas e quando a lista de tarefas possuir conte√∫do? Qual o retorno esperado?

Vamos criar uma lista de tarefas, adicionaremos conte√∫do a ela e este conte√∫do deve ser retornado.

Para fazermos esta checagem, vamos pegar uma tarefa da lista e verificar os seus campos.

O teste automatizado para isto pode ser escrito da seguinte maneira.

```python
def test_quando_listar_tarefas_a_tarefa_retornada_deve_possuir_id():
    TAREFAS.append({"id": 1})
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert "id" in resposta.json().pop()
    TAREFAS.clear()
```

‚ùå Rodou os testes? Pois √©, est√£o quebrando novamente pois TAREFAS n√£o foi definido.

Vamos l√° no arquivo `gerenciador.py` e defini-lo.

```python
# ...
TAREFAS = {}
# ...
```

!!! info
    N√£o esque√ßa de ir no arquivo de testes e importar TAREFAS do gerenciador

`from gerenciador_tarefas.gerenciador import app, TAREFAS`

‚ùå Os testes ainda est√£o quebrando?

Sim, mas agora o erro √© outro. O erro mostrado √© `IndexError: pop from empty list`, e isto ocorre porque l√° no gerenciador ainda estamos retornando uma lista vazia e n√£o a lista de tarefas.

Vamos modificar isto como abaixo:

```python
@app.get("/tarefas")
def listar():
    return TAREFAS
```

Repita este processo para cada um dos campos de uma tarefa, ent√£o teremos que verificar titulo, descri√ß√£o e o estado da tarefa.

No fim nos testes ficam:

```python
from fastapi.testclient import TestClient
from fastapi import status
from gerenciador_tarefas.gerenciador import app, TAREFAS


def test_quando_listar_tarefas_devo_ter_como_retorno_codigo_de_status_200():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.status_code == status.HTTP_200_OK


def test_quando_listar_tarefas_formato_de_retorno_deve_ser_json():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert resposta.headers["Content-Type"] == "application/json"


def test_quando_listar_tarefas_retorno_deve_ser_uma_lista():
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert isinstance(resposta.json(), list)


def test_quando_listar_tarefas_a_tarefa_retornada_deve_possuir_id():
    TAREFAS.append({"id": 1})
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert "id" in resposta.json().pop()
    TAREFAS.clear()


def test_quando_listar_tarefas_a_tarefa_retornada_deve_possuir_titulo():
    TAREFAS.append({"titulo": "titulo 1"})
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert "titulo" in resposta.json().pop()
    TAREFAS.clear()


def test_quando_listar_tarefas_a_tarefa_retornada_deve_possuir_descricao():
    TAREFAS.append({"descricao": "descricao 1"})
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert "descricao" in resposta.json().pop()
    TAREFAS.clear()


def test_quando_listar_tarefas_a_tarefa_retornada_deve_possuir_um_estado():
    TAREFAS.append({"estado": "finalizado"})
    cliente = TestClient(app)
    resposta = cliente.get("/tarefas")
    assert "estado" in resposta.json().pop()
    TAREFAS.clear()

```

E nosso c√≥digo:

```python
from fastapi import FastAPI


app = FastAPI()

TAREFAS = []


@app.get("/tarefas")
def listar():
    return TAREFAS
```

‚úÖ Os testes est√£o funcionando? Parab√©ns! üëè üëè üëè

## üîß Testando manualmente

Para testar nossa aplica√ß√£o manualmente, precisamos colocar nossa aplica√ß√£o no ar.

O comando para isto √© `uvicorn --reload gerenciador_tarefas.gerenciador:app`.

Voil√†, sua aplica√ß√£o est√° no ar. [Clique aqui](http://localhost:8000/tarefas) para abrir no navegador.

![implementa√ß√£o da listagem de tarefas](imgs/listar_tarefas_vazio.png "implementa√ß√£o da listagem de tarefas")

Como adicionamos a op√ß√£o `--reload`, cada vez que modificamos o c√≥digo, o resultado √© modificado tamb√©m, sem precisar desligar e rodar de novo a aplica√ß√£o.

Experimente adicionar tarefas na lista.

```python
TAREFAS = [
    {
        "id": "1",
        "titulo": "fazer compras",
        "descri√ß√£o": "comprar leite e ovos",
        "estado": "n√£o finalizado",
    },
    {
        "id": "2",
        "titulo": "levar o cachorro para tosar",
        "descri√ß√£o": "est√° muito peludo",
        "estado": "n√£o finalizado",
    },
    {
        "id": "3",
        "titulo": "lavar roupas",
        "descri√ß√£o": "est√£o sujas",
        "estado": "n√£o finalizado",
    },
]
```

![implementa√ß√£o da listagem de tarefas preenchido](imgs/listar_tarefas_preenchido.png "implementa√ß√£o da listagem de tarefas preenchido")

Uma outra op√ß√£o √© navegar na sua aplica√ß√£o atrav√©s da [documenta√ß√£o](http://localhost:8000/docs) que √© gerada automaticamente.

![documenta√ß√£o da listagem de tarefas](imgs/documentacao_listar.png "documenta√ß√£o da listagem de tarefas")

## Salvando a vers√£o atual do c√≥digo

Com tudo terminado, vamos salvar a vers√£o atual do c√≥digo.

Primeiro passo √© checar o que foi feito at√© agora:

```bash
$ git status
On branch main
Your branch is up to date with 'origin/main'.

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	gerenciador_tarefas/
	tests/

nothing added to commit but untracked files present (use "git add" to track)
```

Vemos dois diret√≥rios n√£o rastreados e precisamos avisar ao controle de vers√£o para monitora-los.

`$ git add gerenciador_tarefas tests `

üíæ Agora vamos marcar esta vers√£o como salva.

`git commit -m "Adiciona recurso de listar tarefas"`

üîß Por fim envie ao GitHub a vers√£o atualizada do projeto.

`git push`

üòé Parab√©ns! Sua aplica√ß√£o est√° tomando forma! J√° pensou se toda vez que envi√°ssemos uma nova vers√£o para o GitHub, ele verificasse para mim se os testes est√£o passando? Vamos aprender a ter integra√ß√£o cont√≠nua de c√≥digo!?
